---
source_image: "email-screenshot+letter__EFTA01790457_20260130_p002_i001.png"
source_pdf: "EFTA01790457.pdf"
method: pdf_text
words: 581
confidence: 1.00
extracted: 2026-02-13T17:47:47.368622
---

"reducing" =ind and universe to regular and stochastic changes in patterns of =nformation (aka computation) might 
even sound offensive. 
By the way, the first Al optimist was probably LaMettrie. His small, =itty and much maligned book "L'homme machine" 
(1747) is full of =odern insights, such as the continuum between humans and great apes, =he futility of the scholastic 
method (building on authority instead of =xperiment), the nonsense of dualism, the idea that machines need not be 
=hysical but can be mathematical, and so on. When he predicts that =aucanson's automatons herald the imminent 
arrival of machines that =ill actually speak and understand, he sounds almost like Ray Kurzweil =-) LaMettrie had 
relatively little impact in his time; his open atheism and =ejection of souls, vitalism, etc. made him a persona non grata. 
Perhaps not entirely unlike Minsky among continental philosophers of =ind... And the impact of the Lighthill report has 
probably a lot to do =ith the offense that people take at the notion of mind as machine. 
> This strikes me as very much like the process we go through with the =efining Al tasks like chess or Jeopardy or car 
driving. We start off "relieving that these are tasks that only human intelligence can achieve. =hen we build 
computational systems that can do them. Those systems are =ften inspired by the way humans achieve the tasks, but in 
the end work =n extremely non-human ways. Google's self-driving car uses massive =atellite data and laser scanning to 
drive, Deep Blue doesn't play chess =ike a human does. 
Applied Al has the big benefit that it does not offend anyone. The =pplications you mentioned are usually 
straightforward engineering, i.e. =hey do not even attempt to mimic human intelligence, but only look for =ays to solve 
the task at hand in the best possible way. 
If we want these applications to teach us something about the mind, we =eed to impose additional constraints. For 
instance, in robotic soccer, =e tended to brute-force problems with sensing the robot's environment =ith hardware 
(laser scanners, sonar, additional cameras, better CPUs). =he exception was the Aibo league, which had to make do with 
Sony's =og robots. With only a terrible, shaky camera, little memory and a slow =PU, the programmers had to come up 
with attentional processing, anytime =lgorithms that deliver better results over time, resource allocation =tc. I found 
that the most constrained robots enforced the most =nteresting solutions (of course, without getting much credit for it). 
Another problem with the typical applications is that they usually =eplace or reproduce human performance, i.e. they 
need to start out with =he abilities of a trained adult. Instead, we might want to look at =eproducing the path that 
human children take towards intelligence, the =utonomous process by which children learn to make sense of the world, 
=cquire a language, visual and conceptual grammars and so on. After =bout 3.5 years of swimming in massive flows of 
data, a child won't do =ell at Jeopardy, traffic navigation or chess yet, but can already watch =he first Star Wars movie 
and afterwards explain that Darth Vader =estroyed princess Leia's planet, and that he needs a laser sword. All =ognitive 
development afterwards is probably trivial ;-) I think this is =he kind of performance we should be looking for when we 
try to build =1. 
Cheers, 
Joscha 
<?xml version=.0" encoding=TF-8"?> 
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"> 
<pl ist version=.0"> 
<dict> 
<key>date-last-viewed</key> 
<integer>0</integer> 
<key>date-receivedgkey> 
<integer>1382838458</integer> 
<key>flags</key> 
<integer>8623750161</integer> 
2 
EFTA_R1_00118619 
EFTA01790458
