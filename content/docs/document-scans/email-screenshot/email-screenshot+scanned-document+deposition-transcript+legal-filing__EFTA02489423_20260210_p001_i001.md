---
source_image: "email-screenshot+scanned-document+deposition-transcript+legal-filing__EFTA02489423_20260210_p001_i001.png"
source_pdf: "EFTA02489423.pdf"
method: pdf_text
words: 528
confidence: 1.00
extracted: 2026-02-13T17:48:45.487057
---

From: 
on behalf of Ben Goertzel 
Sent: 
on ay, eptem er , 015 1:16 AM 
To: 
Jeffrey E. 
Subject: 
Re: 
I think that "learning language like a baby" is a fantastic and important research area ... I'm just not (at this moment) 
seeing how to boil it down into a crisply-defined •challenge• that neatly gauges incremental progress .... 
"Doing X" is straightforward to measure from a challenge-problem context, whereas "Learning X" is harder to measure 
in a challenge-problem context, because eager competitive contestants can always program most of X into their system 
and then make their system kinda-learn the rest.... Diamandis's X-Prize Foundation has asked me for help with 
formulating an AGI X Prize multiple times over the years, and I never had anything great to suggest for precisely this 
reason. Of course a prize for "achieving human level AGI" would make 
sense-- but that's such a big achievement that if you get there, the 
prize will be the least of your worries anyway! It's measuring 
incremental progress in a rigorous and cheating-proof way that's so tricky... 
About how babies learn language. Clearly it's a lot about embodiment and social interaction, right? You may have read 
Tomassello, 
"Constructing a Language"? 
(not Al, cognitive science, but 
good...) ... And I think rich perceptual stimuli and some degree of 
motoric affordances are important. So to really emulate or 
understand learning language like a baby, I suspect it's necessary to go robotic (though, certainly, not necessarily 
HUMANOID-robotics). 
Joscha may disagree on this point, I'm unsure.... 
The point is you 
need a rich stream of perceptual data, whose interrelationships can ground the interrelationships between linguistic 
constructs; and you need actions to be taken based on this perceptual data, to give grounding for the structure of 
sentences (which is action-based at the 
base, with the VERB at the center of the sentence, etc.). In theory 
this could all be done in a virtual world (I mean: in theory we might all live in a virtual world!!), but it might need to be a 
lot more data-rich than Minecraft... 
The Europeans are pushing in this direction with iCub, but very slowly, as always w/ these massive multi-university 
multi-nation 
government boondoggle projects. Aldebaran Robotics was doing 
something in this direction, but that research group was shut down 
when they were acquired by Softbank a year or two ago. Google, 
oddly, seems not to be doing this sort of thing (yet) --- even though they have some great folks doing computational 
linguistics (including unsupervised learning of syntax from corpora) and they have just bought a raft of robotics 
companies... 
So my own feeling is that to make progress on "learning language like a baby" you want to use a simple robot that needs 
to do stuff in an environment, and needs to learn language to achieve its goals in that 
environment.... Could be a simple rolling robot with a camera, 
microphone, speaker and arm, moving around in a robot-lab environment (but NOT in a "playroom" denuded of 
diversity of objects and events)... or could be a simple humanoid... 
One idea would be to go back to the idea of a child IQ test. The 
EFTA_R1_01609863 
EFTA02489423
