---
source_image: "deposition-transcript+scanned-document+legal-filing+typed-page__EFTA01734595_20260130_p003_i001.png"
source_pdf: "EFTA01734595.pdf"
method: pdf_text
words: 511
confidence: 1.00
extracted: 2026-02-13T16:55:38.980256
---

http://â€¢gi-conference.org/2012/
Independently of you attending, if you were able to help with a small amount of 
sponsorship money that would be great. A sponsorship of $3000 or $5000 would 
definitely help the conference pay its bills. Oxford is a swanky location but doing 
things there is pretty expensive. 
The fact that we've gotten offered more Hong Kong ITF funding is wonderful, but, 
it's not really enough funding to do what needs doing. So David Hanson and I have 
written up a research proposal for the OpenCog/Robokind/DeSTIN work, which I 
attach here, along with a brief paper on the vision-cognition integration aspect. Our 
goal (which may be hard to achieve) is to raise $350,000 for this, in addition to the 
ITF funding. 
Obviously, if your foundation would be willing to fund this, that would be awesome. 
With this money PLUS the already-offered Hong Kong ITF funding, we could make a 
more emphatic push toward getting OpenCog to control a Hanson Robokind in 
interesting ways. As your profile seems to focus on funding universities, the money 
could perhaps be worked via a donation to Hong Kong Polytechnic University, 
where the OpenCog project is currently funded. 
My thinking on the robotics collaboration is as follows. First, I think that having the 
AGI able to ingest and interact with real-world *perceptual data* is important. An 
intelligent system tends to adapt itself to whatever environment and problems it is 
given. So if an intelligent system lives and exists and learns only in a video game 
world full of blocks, it's not going to self-organize the internal structures and 
dynamics needed to deal with the real human world. The video game context is 
great as a prototyping domain, to help one refine one's AGI thinking and test one's 
code. But it's not going to get us to human-level AGI. I don't think robotics is the 
*only* path to human-level and transhuman AGI, but I think it's the most clearly 
comprehensible path. I understand how to create AGI in a system with vaguely 
human-like perception and actuation, because I can use the human mind as an 
analogue. I understand much less well how to create other sorts of AGI systems, 
though I have no doubt they are possible. So I think we should start with vaguely 
human-like systems, which are the "easiest" to approach, and then move on from 
there... 
Secondly, I think that -- from a purely "marketing" perspective (where I mean 
marketing within academia and the scientific world, as well as more broadly) --
having a cute little boy humanoid robot that can walk around and talk and interact, 
will do wonders for getting buy-in for AG!. This will be what I have called the "AGI 
Sputnik" moment (a term I coined in this somewhat rambling interview, 
ktspii/hplusmagazine.com/2011/03/30/seeking-the-sputnik-of-agin. If we can 
pull this off, getting AGI funding will not be a problem anymore. IBM's Watson and 
Google's self-driving cars have already made the world more optimistic about Al, in 
the last year or two. A palpably intelligent little humanoid robot can be the next 
EFTA_R1_00012866 
EFTA01734597
