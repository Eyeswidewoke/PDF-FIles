---
source_image: "deposition-transcript+book-page+legal-filing__EFTA02702508_20260210_p009_i001.png"
source_pdf: "EFTA02702508.pdf"
method: pdf_text
words: 901
confidence: 1.00
extracted: 2026-02-13T16:20:34.049004
---

scrupulous in the twilight—
the price of gold chases 
the way of the world in power 
a reasonable assumption—
by myself, 
sampling in chocolate 
with the best set of sonic similarities to the noun "computer 
programmer": "provoked me to anger." 
I can ask InkWell specifically to surprise me because it has 
ngrams for millions of texts written since 1890 118) including 
frequencies of appearance, and I can ask for rare or never-seen 
combinations. I can ask InkWell to search for unusual syn-
onyms; I can ask it to write unlike particular writers. When 
there are dozens of constraint types with both positive and 
negative weights, there are few limits to surprise. 
The poets were surprised, too. CG: "'sampling in chocolate'" 
is surprising language"; "'guitar-shaped coloring' is surpris-
ing. It evokes brown / beige because guitars are made of wood, 
and it's interesting / surprising that a shape 
could evoke a color." DC: "I don't know ex-
actly the sense of this, but i like the surprise. 
the sound, the sonic surprise of 'scrupulous 
in the twilight'"; "i recognize all of it as poetry because of the 
surprisingness of the language." 
I asked about the use of language in the poems. CG: "Awe-
some." DC: "Good noise. Surprising in a good way. a few days—
intriguing. Lots of variety. Big, small, long short, y "Ws° • 
evaluations with Monte-Carlo rollouts. Our 
uitar-sha
browsing g 
p 
loud, soft, complex, plain. Not a single track." 
ed coloring program AlphaGo integrates these components 
purpose-built software robots like those that play checkers, 
chess, backgammon, and Go. These are intended to show that 
human-level expertise in narrow domains can be exhibited or 
at least simulated. The Jeopardy!-playing Watson is close to 
these narrow robots because the domain is trivia—the sort of 
stuff that Google is good at finding. Watson moves closer to 
the universal notion of thinking that Turing was approaching. 
Turing ended his essay with an appeal to a learning ap-
proach to get machines close to human abilities. As noted 
learning is generally taken as machine learning these days. 
As I write this essay, AlphaGo just marched to victory against 
a very strong human Go player (Lee Se-dol, a 9-dan profes-
sional Go player). As David Silver et al wrote [201: 
We have developed, for the first time, effective move 
selection and position evaluation functions for Go, 
based on deep neural networks that are trained by a 
novel combination of supervised and reinforcement 
learning. We have introduced a new search algorithm 
that successfully combines neural network 
The Turing Test is of course bogus. At least in the form Tur-
ing envisioned. A common strategy for passing is to dodge 
questions. typically using humor and distractions. Turing's 
own example shows a dodge as an accept-
able response; "Count me out on this one. 
I never could write poetry." 
Beginning in 2008 a series of practical 
Turing tests have been conducted under academic scrutiny, 
run using the best interpretation of Turing's specifications. In 
June 2014 an extensive set of interrogations were conducted 
at the Royal Society [19J. This produced ISO parallel tran-
scripts, each of which contains a single interrogator posing 
questions for five minutes to a human and a chatterbot, with 
the responses being returned side-by-side at the same time on 
the same screen. In the Appendix you can see a sample par-
allel transcript. In this sample the LHS (left-hand side of the 
screen) was a female adult human, and the RHS was Eugene, 
a chatterbot. The judge misjudged the LHS to definitely be a 
machine and the RHS to be a non-native English speaking 
human. The judge got it backward. The human on the LHS 
had weak responses while the machine on the RHS tried to 
dominate the conversation and was definitely more lively than 
the LHS. The chatterbot pretending to be Eugene Goostman, 
a 13-year-old Ukrainian boy, was declared to have passed the 
Turing Test for having fooled more than 30% of the judges. 
Part of Thring's idea was that the unexpected scope of ques-
tions would be the key to deciding whether the computer was 
thinking sufficiently like a human. This is in contrast with the 
9 
together, at scale, in a high-performance tree 
search engine. 
-Silver et al, Mastering the Game of Go with Deep Neural 
Networks and Tree Search, 2016 
Here the issue of viva vice comes up—how would AlphaGo 
explain why it made a particular move? Answers of the form 
"7 is better than 6" won't work well, but perhaps the people 
who developed AlphaGo can intuit such answers. AlphaGo 
lost game four, and here is what was reported in the press 1211: 
According to tweets from DeepMind founder Denies 
Hassabis, however, this time AlphaGo really did make 
mistakes. The Al "thought it was doing well, but got 
confused on move 8Z" Hassabis said, later clarifying 
that it made a mistake on move 79 but only realized 
its error by 87. 
-httpwwww.theverge.com/2016/3/13/11184328/alphago-
deepinind-go-rnatch-4-result 
And Ttiring would seem to respond when he wrote: 
May not machines carry out something which ought 
to be described as thinking but which is very different 
front what a man does? This objection is a very strong 
one, but at least we can say that if nevertheless, a ma-
chine can be constructed to play the imitation game 
satisfactorily, we need not be troubled by this objection. 
-Turing, Computing Machinery and Intelligence, 1950 
EFTA_R1_02074947 
EFTA02702516
