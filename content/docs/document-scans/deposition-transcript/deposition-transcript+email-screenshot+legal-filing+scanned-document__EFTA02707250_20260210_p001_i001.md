---
source_image: "deposition-transcript+email-screenshot+legal-filing+scanned-document__EFTA02707250_20260210_p001_i001.png"
source_pdf: "EFTA02707250.pdf"
method: pdf_text
words: 501
confidence: 1.00
extracted: 2026-02-13T16:38:17.115212
---

From: 
on behalf of Ed Boyden 
Sent: 
Tuesday, May 28, 2013 10:55 AM 
To: 
Jeffrey Epstein 
Subject: 
Re: Thanks 
The piano itself isn't quite the analogy to the brain, because it has no memory, independent of the human playing it. 
After the finger lifts, the strings quiets down. 
So I am assuming that we need to model the human playing the piano? 
Suppose, say, we want to understand what emotion is generating the music. 
If we could measure activity in the brain of the person playing the piano, and could predict what melody or sequence of 
notes the person would play, based on that activity, then we could infer that the internal brain activity was causing the 
melody. This inference might be convertible into proof, if we were to stimulate the brain and play back an activity 
pattern into the brain, seeing how that would alter the melody being played. And if we have a molecular map of the 
brain, which we could simulate on a computer, we could through biophysical simulation begin to see how the molecular 
interactions between cells, yield dynamics of the network, which then yield the sequence of finger commands that yield 
the music. 
Thus, the finger is the interface between two dynamical systems -- the brain and the piano. Each of those dynamical 
systems has a physical implementation that can be modeled, if we have three things: 
-- mechanistic maps (piano: string lengths, material properties, etc.) 
-- dynamics (piano: the finger movements and temporal scuplting) 
-- control (piano: we can modulate the human and see how the music changes) 
Ed 
On Tue, May 28, 2013 at 6:46 AM, Jeffrey Epstein <jeevacation@gmail.com> wrote: 
> give me a piano music analogy, / watching the strings, ? after key 
> inputs,? interesting byt not dispositive of anything meaningful 
> On Tue, May 28, 2013 at 6:40 AM, Ed Boyden 
wrote: 
» I agree we need a top-down! Two thoughts: 
» -- Yes, developing mapping circuit technology and then applying it 
» to simple behaviors -- hard wired aversive stuff -- is indeed a way 
» to go. As we plan out these mapping technologies, we're actually 
» beginning experiments to map out these aversive things too. We are 
» collaborating with many groups along these lines. We need to finish 
» the fundamental technology building so that we can obtain maps at the 
» right level, and then we can acquire datasets that are compatible 
» with top-down theory, to be sure. 
» -- Another way to think top-down is to work our way inwards, from 
» the observables. We know that behavior -- movement, speech, other 
» action 
» -- is observable; if a feeling or thought is prominent enough, it 
» will be manifest through these channels as an observable. Thus we 
» can also try to infer internal states by their effects on 
» observables, and then to associate neural activity with these 
» internal states and observables. In theory this should scale to 
EFTA_R1_02104539 
EFTA02707250
